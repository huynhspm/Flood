_target_: src.models.TideModule

optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 0.001
  weight_decay: 0.0

scheduler:
  _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  _partial_: true
  mode: min
  factor: 0.1
  patience: 10

net:
  _target_: src.models.net.Transformer1D
  d_input: 2
  d_cond: null
  d_model: 8
  month_embedder: 
    _target_: src.models.net.PositionalEncoding
    d_model: ${model.net.d_model}
    max_len: 15
    frequency: 5000.0
    amplitude: 2.0
  day_embedder: 
    _target_: src.models.net.PositionalEncoding
    d_model: ${model.net.d_model}
    max_len: 1500
    frequency: 10000.0
    amplitude: 1.0
  input_encoder:
    _target_: torch.nn.TransformerEncoder
    encoder_layer:
      _target_: torch.nn.TransformerEncoderLayer
      d_model: ${model.net.d_model}
      nhead: 4
      dim_feedforward: 16
      dropout: 0.2
      batch_first: True
    num_layers: 3
  cond_encoder: null
  decoder:
    _target_: torch.nn.TransformerDecoder
    decoder_layer: 
      _target_: torch.nn.TransformerDecoderLayer
      d_model: ${model.net.d_model}
      nhead: 4
      dim_feedforward: 16
      dropout: 0.5
      batch_first: True
    num_layers: 2

# compile model for faster training with pytorch 2.0
compile: false
